{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath, is_testing=False):\n",
    "    # Read the CSV file \n",
    "    if is_testing:\n",
    "        data = pd.read_csv(filepath, header=None)\n",
    "        data.columns = ['Date', 'ItemName', '0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "    else:\n",
    "        data = pd.read_csv(filepath)\n",
    "        data.drop(['Location'], axis=1, inplace=True)\n",
    "\n",
    "    # Replace non-numeric values with NaN\n",
    "    non_numeric = {'#': np.nan, '*': np.nan, 'x': np.nan, 'A': np.nan}\n",
    "    data.replace(non_numeric, inplace=True)\n",
    "\n",
    "    # Convert the columns to numeric, except 'Location', 'Date', and 'ItemName'\n",
    "    numeric_columns = data.columns.difference(['Location', 'Date', 'ItemName'])\n",
    "    data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Fill NaN values with the mean of their respective columns\n",
    "    data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].median())\n",
    "\n",
    "    \n",
    "\n",
    "    # Strip the 'ItemName' column\n",
    "    data['ItemName'] = data['ItemName'].str.strip()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Use the function to load and preprocess your data\n",
    "data = load_and_preprocess_data('train.csv')\n",
    "test_data = load_and_preprocess_data('test.csv', is_testing=True)\n",
    "print(data.head())\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_targets(dataframe, is_train=True):\n",
    "    # Initialize lists to store features and targets\n",
    "    features_list = []\n",
    "    target_list = []\n",
    "\n",
    "    # Unique dates in the DataFrame\n",
    "    unique_dates = dataframe['Date'].unique()\n",
    "\n",
    "    # Loop through each date to extract features and target\n",
    "    for date in unique_dates:\n",
    "        # Filter the DataFrame for the current date\n",
    "        daily_data = dataframe[dataframe['Date'] == date]\n",
    "\n",
    "        # Ensure that the data is sorted by ItemName to maintain consistent feature order\n",
    "        daily_data = daily_data.sort_values('ItemName')\n",
    "\n",
    "        # Extract the feature data for hours 0-9 for all elements\n",
    "        daily_features = daily_data.iloc[:, 2:11].values.flatten()  # Assuming 3rd column is hour 0\n",
    "\n",
    "        # Add the extracted features to the features list\n",
    "        features_list.append(daily_features)\n",
    "\n",
    "        if not is_train:\n",
    "            continue\n",
    "\n",
    "        # Extract the target data (PM2.5 at 10 AM)\n",
    "        pm25_data = daily_data[daily_data['ItemName'] == 'PM2.5']\n",
    "        pm25_at_10am = pm25_data.iloc[0, 11] if not pm25_data.empty else np.nan  # Assuming 12th column is hour 10\n",
    "\n",
    "        # Add the target value to the target list\n",
    "        target_list.append(pm25_at_10am)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    target_array = np.array(target_list)\n",
    "\n",
    "    return features_array, target_array\n",
    "\n",
    "\n",
    "# Now you can call the function with your DataFrame\n",
    "features, targets = extract_features_targets(data)\n",
    "test_features, _ = extract_features_targets(test_data, is_train=False)\n",
    "\n",
    "# Print shapes to confirm dimensions\n",
    "print('Features shape:', features.shape)\n",
    "print('Targets shape:', targets.shape)\n",
    "print('Test Features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(features)\n",
    "X = X.astype(float)\n",
    "y = np.array(targets)\n",
    "y = y.astype(float)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "X_test = X_test.astype(float)\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "print(X_test[0])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, length_of_features):\n",
    "    b = 0.0\n",
    "    w = np.ones(length_of_features)\n",
    "    lr = 0.005\n",
    "    epoch = 5000000\n",
    "    b_lr = 0.0\n",
    "    w_lr = np.zeros(length_of_features)\n",
    "    lambda_value = 0\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        # y_data = b + w * x_data\n",
    "        error = y_data - b - np.dot(x_data, w) \n",
    "\n",
    "        # Calculate gradient\n",
    "        b_grad = -2 * np.sum(error) * 1\n",
    "        w_grad = -2 * np.dot(error, x_data) + 2 * lambda_value * w\n",
    "        \n",
    "        # Update sum of squares of gradients\n",
    "        b_lr = b_lr + np.square(b_grad)\n",
    "        w_lr = w_lr + np.square(w_grad)\n",
    "\n",
    "        # Update parameters\n",
    "        b = b - lr / np.sqrt(b_lr) * b_grad\n",
    "        w = w - lr / np.sqrt(w_lr) * w_grad\n",
    "        \n",
    "        loss = np.mean(np.square(error)) + lambda_value * np.sum(np.square(w))\n",
    "        \n",
    "        if (e + 1) % 1000 == 0:\n",
    "            print(f'epoch {e + 1}: Loss {np.sqrt(loss)}')\n",
    "    return b, w\n",
    "\n",
    "n_features = X.shape[1]  \n",
    "bias, weights = train(X, y, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "test_predictions = X_test.dot(weights) + bias\n",
    "\n",
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "header = ['index', 'answer']\n",
    "data = [['Alex', 62, 80], ['Brad', 45, 56], ['Joey', 85, 98]]\n",
    "filename = 'output.csv'\n",
    "with open(filename, 'w') as file:\n",
    "    csvwriter = csv.writer(file)\n",
    "    csvwriter.writerow(header)\n",
    "    for idx, row in enumerate(test_predictions):\n",
    "        file.write(f\"index_{idx}\" + ', ' + str(row))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
